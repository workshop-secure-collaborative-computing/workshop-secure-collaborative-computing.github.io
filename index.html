<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>ICLR 2025 Workshop on Reasoning and Planning for Large Language Models</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,700,700i|Raleway:300,400,500,700,800" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">
  
  <!-- Custom CSS for Schedule Table -->
  <style>
    .schedule-table {
      width: 100%;
      border-collapse: collapse;
      background: #fff;
      font-family: Arial, sans-serif;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
      margin: 20px 0;
    }
    .schedule-table th,
    .schedule-table td {
      padding: 12px 15px;
      border-bottom: 1px solid #ccc;
      text-align: left;
    }
    .schedule-table th {
      background-color: #f7f7f7;
      font-weight: bold;
    }
    .schedule-table tbody tr:nth-child(even) {
      background-color: #f9f9f9;
    }
    .schedule-table tbody tr:hover {
      background-color: #f1f1f1;
    }
    /* 响应式设计 */
    @media (max-width: 768px) {
      .schedule-table th,
      .schedule-table td {
        padding: 10px;
      }
    }
  </style>
  <!-- =======================================================
  * Template Name: TheEvent
  * Updated: Sep 18 2023 with Bootstrap v5.3.2
  * Template URL: https://bootstrapmade.com/theevent-conference-event-bootstrap-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="d-flex align-items-center ">
    <div class="container-fluid container-xxl d-flex align-items-center">

      <div id="logo" class="me-auto">
        <!-- Uncomment below if you prefer to use a text logo -->
        <!-- <h1><a href="index.html">The<span>Event</span></a></h1>-->
        <a href="index.html" class="scrollto"><img src="assets/img/logo.png" alt="" title=""></a>
      </div>

      <nav id="navbar" class="navbar order-last order-lg-0">
        <ul>
          <li><a class="nav-link scrollto active" href="#hero">Home</a></li>
          <li><a class="nav-link scrollto" href="#about">About</a></li>
          <li><a class="nav-link scrollto" href="#schedule">Schedule</a></li>
          <li><a class="nav-link scrollto" href="#topic">Topics</a></li>
          <li><a class="nav-link scrollto" href="#cfp">Call for Papers</a></li>
          <li><a class="nav-link scrollto" href="#grant">Student Registration Grant</a></li>
          <li><a class="nav-link scrollto" href="#speakers">Speakers</a></li>
          <li><a class="nav-link scrollto" href="#organizers">Organizers</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav>

    </div>
  </header><!-- End Header -->

  <!-- ======= Hero Section ======= -->
  <section id="hero">
    <div class="hero-container" data-aos="zoom-in" data-aos-delay="200">
      <h1 class="mb-4 pb-0" style="text-transform: none;">
        Reasoning and Planning for Large Language Models<br>
        ICLR 2025, April 28 2025, Singapore
      </h1>
      <div class="social-links" style="margin-top: 25px;">
        <a href="https://x.com/ZhiyuanCS/status/1866401974792691742" target="_blank" rel="noopener noreferrer" style="margin-right: 15px; text-decoration: none; color: #1DA1F2;">
          Twitter
        </a>
        <a href="https://openreview.net/group?id=ICLR.cc/2025/Workshop/LLM_Reason_and_Plan&referrer=%5BHomepage%5D(%2F)#tab-your-consoles" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: #1DA1F2;">
          OpenReview
        </a>
      </div>
    </div>
  </section>
  <!-- End Hero Section -->

  <main id="main">

    <!-- ======= About Section ======= -->
    <section id="about">
      <div class="container position-relative" data-aos="fade-up">
        <div class="row">
          <div class="col-lg-12">
            <h2>About The Workshop</h2>
            <p style="font-size: 18px;">This workshop explores the growing capabilities of large language models (LLMs), such as OpenAI's o1 model, in reasoning, planning, and decision-making, highlighting recent advances and challenges. We aim to examine how reinforcement learning methods, post-training optimization, and efficient inference techniques can further enhance LLMs' reasoning capabilities. Topics include training approaches for enhancing reasoning and planning abilities, scaling inference for complex tasks, developing robust benchmarks, and extending LLMs to multi-modal and embodied environments. We will also discuss broader themes such as causal reasoning, collaborative multi-agent systems, uncertainty, and explainability to offer insights and guidance for the further development of reasoning and planning in LLMs.</p>
          </div>
        </div>
      </div>
    </section>
    <!-- End About Section -->

    <!-- ======= Schedule Section ======= -->
    <section id="schedule" style="padding-top: 20px;">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Schedule</h2>
        </div>
        <div class="table-responsive">
          <table class="schedule-table table align-middle">
            <thead>
              <tr>
                <th>Time (SGT)</th>
                <th>Session</th>
                <th>Speaker</th>
                <th>Talk Title</th>
                <th>Host</th>
              </tr>
            </thead>
            <tbody>
              <!-- 非 contributed talk 部分 -->
              <tr>
                <td>08:30 – 08:40</td>
                <td>Introduction and Opening Remarks</td>
                <td>N/A</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>08:40 – 09:10</td>
                <td>Invited Talk 1</td>
                <td>Yuandong Tian (Meta)</td>
                <td></td>
                <td>TBD</td>
              </tr>
              <tr>
                <td>09:10 – 09:40</td>
                <td>Invited Talk 2</td>
                <td>Guy Van den Broeck</td>
                <td></td>
                <td>Jiaying Wu</td>
              </tr>
              <tr>
                <td>09:40 – 10:10</td>
                <td>Invited Talk 3</td>
                <td>Yarin Gal/Hongyu Ren (OpenAI)</td>
                <td></td>
                <td>TBD</td>
              </tr>
              <tr>
                <td>10:10 – 10:40</td>
                <td>Invited Talk 4</td>
                <td>Natasha Jaques (UW &amp; Google DeepMind)</td>
                <td></td>
                <td>Yali Du</td>
              </tr>
              <tr>
                <td>10:40 – 11:40</td>
                <td>Panel Discussion</td>
                <td>All Speakers</td>
                <td></td>
                <td>Xidong Feng</td>
              </tr>
              <tr>
                <td>11:40 – 13:30</td>
                <td>Poster Session 1 and Lunch Break</td>
                <td>/</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>13:45 – 14:15</td>
                <td>Invited Talk 6</td>
                <td>Bo An (NTU)</td>
                <td></td>
                <td>Yali Du</td>
              </tr>
              <!-- Oral Paper Presentation 部分 -->
              <tr>
                <td>14:15 – 14:25</td>
                <td>Oral Paper Presentation 1</td>
                <td>TBD</td>
                <td>126: When More is Less: Understanding Chain-of-Thought Length in LLMs</td>
                <td>Jiaying Wu</td>
              </tr>
              <tr>
                <td>14:25 – 14:35</td>
                <td>Oral Paper Presentation 2</td>
                <td>TBD</td>
                <td>102: RL-STaR: Theoretical Analysis of Reinforcement Learning Frameworks for Self-Taught Reasoner</td>
                <td>Jiaying Wu</td>
              </tr>
              <tr>
                <td>14:35 – 14:45</td>
                <td>Oral Paper Presentation 3</td>
                <td>TBD</td>
                <td>128: Feedback-Aware Monte Carlo Tree Search for Efficient Information Seeking in Goal-Oriented Conversations</td>
                <td>Jiaying Wu</td>
              </tr>
              <tr>
                <td>14:45 – 14:55</td>
                <td>Oral Paper Presentation 4</td>
                <td>TBD</td>
                <td>147: Offline Reinforcement Learning for LLM Multi-Step Reasoning</td>
                <td>Jiaying Wu</td>
              </tr>
              <tr>
                <td>14:55 – 16:00</td>
                <td>Poster Session 2</td>
                <td>/</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>16:00 – 16:30</td>
                <td>Invited Talk 7</td>
                <td>Stephen McAleer (OpenAI)</td>
                <td></td>
                <td>Xidong Feng</td>
              </tr>
              <tr>
                <td>16:30 – 17:00</td>
                <td>Invited Talk 8</td>
                <td>Junxian He (HKUST)</td>
                <td></td>
                <td>Bryan Hooi</td>
              </tr>
              <tr>
                <td>17:00 – 17:10</td>
                <td>Oral Paper Presentation 5</td>
                <td>TBD</td>
                <td>162: Rethinking Fine-tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning</td>
                <td>Xidong Feng</td>
              </tr>
              <tr>
                <td>17:10 – 17:20</td>
                <td>Oral Paper Presentation 6</td>
                <td>TBD</td>
                <td>158: Improving Test-Time Search for LLMs with Backtracking Against In-Context Value Verifiers</td>
                <td>Xidong Feng</td>
              </tr>
              <tr>
                <td>17:20 – 17:30</td>
                <td>Oral Paper Presentation 7</td>
                <td>TBD</td>
                <td>152: s1: Simple test-time scaling</td>
                <td>Xidong Feng</td>
              </tr>
              <tr>
                <td>17:30 – 17:40</td>
                <td>Paper Award &amp; Closing Remarks</td>
                <td>N/A</td>
                <td></td>
                <td>Zhiyuan Hu</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </section>
    <!-- End Schedule Section -->

    <!-- ======= Topics Section ======= -->
    <section id="topic" class="section-with-bg">
      <br>
      <br>
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Topics</h2>
          <p>The workshop will cover a range of topics, including but not limited to:</p>
        </div>
        <section id="topics">
          <div class="container">
            <!-- Topic 1 -->
            <div class="row mb-4">
              <div class="col-12">
                <div class="topic-panel interactive-panel p-4 border shadow-sm rounded" style="background: #ffffff;">
                  <b style="font-size: 18px; color: #343a40;">Training Methodologies for Enhancing Reasoning and Planning Capabilities in LLMs:</b>
                  <p style="color: #6c757d; margin-top: 10px;">
                    We will explore the application of RL algorithms and other effective approaches in enhancing LLM reasoning and planning abilities during both pre-training and post-training stages. We will examine how techniques like Reinforcement Learning from Human Feedback (RLHF) can be adapted and expanded for efficient reasoning. Key questions include:
                  </p>
                  <ul style="color: #6c757d;">
                    <li>How can RL and other effective methods be utilized in pre-training to improve reasoning abilities?</li>
                    <li>What post-training approaches (e.g., fine-tuning, RLHF) are most effective for LLM planning tasks?</li>
                    <li>How can synthetic data generation and self-supervised training enhance LLM reasoning and planning?</li>
                  </ul>
                </div>
              </div>
            </div>

            <!-- Topic 2 -->
            <div class="row mb-4">
              <div class="col-12">
                <div class="topic-panel interactive-panel p-4 border shadow-sm rounded" style="background: #ffffff;">
                  <b style="font-size: 18px; color: #343a40;">Inference Time Scaling for Complex Reasoning Tasks:</b>
                  <p style="color: #6c757d; margin-top: 10px;">
                    We will discuss challenges and innovations in scaling up reasoning during inference. As models become larger and tasks more complex, efficient inference mechanisms are critical. Topics of interest include:
                  </p>
                  <ul style="color: #6c757d;">
                    <li>What are the most promising methods for scaling inference times in reasoning-heavy tasks?</li>
                    <li>How can models dynamically allocate resources during inference to optimize for reasoning and planning?</li>
                  </ul>
                </div>
              </div>
            </div>

            <!-- Topic 3 -->
            <div class="row mb-4">
              <div class="col-12">
                <div class="topic-panel interactive-panel p-4 border shadow-sm rounded" style="background: #ffffff;">
                  <b style="font-size: 18px; color: #343a40;">Benchmarking Reasoning and Planning:</b>
                  <p style="color: #6c757d; margin-top: 10px;">
                    Developing robust benchmarks for evaluating reasoning and planning in LLMs is critical to track progress. This session will address the need for new metrics and standardized tasks to assess reasoning abilities across different scenarios. Key discussions will include:
                  </p>
                  <ul style="color: #6c757d;">
                    <li>What benchmarks can accurately reflect the reasoning and planning capabilities of LLMs?</li>
                    <li>How do we design tasks that evaluate long-horizon reasoning and complex decision-making?</li>
                  </ul>
                </div>
              </div>
            </div>

            <!-- Topic 4 -->
            <div class="row mb-4">
              <div class="col-12">
                <div class="topic-panel interactive-panel p-4 border shadow-sm rounded" style="background: #ffffff;">
                  <b style="font-size: 18px; color: #343a40;">Multi-modality and Embodiment in LLMs:</b>
                  <p style="color: #6c757d; margin-top: 10px;">
                    As LLMs increasingly integrate with multi-modal environments, reasoning across multiple data types (e.g., vision, sound, text) becomes more essential. This session will explore the application of reasoning and planning in multi-modality and embodied AI systems, including robotics and real-world interactions:
                  </p>
                  <ul style="color: #6c757d;">
                    <li>How can LLMs enhance multi-modal reasoning and planning to better interact with diverse environments?</li>
                    <li>What are the key challenges and opportunities in applying LLMs to multi-modal tasks, including those requiring embodied reasoning?</li>
                  </ul>
                </div>
              </div>
            </div>

            <!-- Topic 5 -->
            <div class="row mb-4">
              <div class="col-12">
                <div class="topic-panel interactive-panel p-4 border shadow-sm rounded" style="background: #ffffff;">
                  <b style="font-size: 18px; color: #343a40;">Exploring Broader Topics in Reasoning and Planning:</b>
                  <p style="color: #6c757d; margin-top: 10px;">
                    In addition to the core themes mentioned above, our discussions will also encompass a broader range of emerging topics, including:
                  </p>
                  <ul>
                    <li><b>Causal Reasoning:</b> How can LLMs move beyond pattern recognition to infer causal relationships?</li>
                    <li><b>Collaborative Reasoning in Multi-Agent Systems:</b> How can LLMs enable multi-agent cooperation for distributed tasks?</li>
                    <li><b>Uncertainty and Robustness:</b> How can LLMs improve reasoning under ambiguous information?</li>
                    <li><b>Human-in-the-Loop Systems:</b> How can human feedback refine LLM decision-making processes?</li>
                    <li><b>Explainability:</b> How can we make LLM reasoning and planning more transparent and interpretable for real-world applications?</li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </section>
      </div>
      <br>
      <br>
    </section>
    <!-- End Topics Section -->

    <section id="cfp">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Call For Papers</h2>
        </div>
        <p>
          The <b>Reasoning and Planning for LLMs@ICLR 2025</b> invites submissions on the development of novel architectures, algorithms, theoretical analyses, empirical studies, and applications in reasoning and planning with LLMs. Submissions must present original, unpublished research.
        </p>
        <h3>Key Dates</h3>
        <ul class="fa-ul">
          <li>
            <span class="fa-li"><i class="fa fa-check"></i></span>
            <b>Paper Deadline</b>: 
            <del>February 2, 2025 (AOE)</del> 
            <span style="color: red;">February 6, 2025 (AOE)</span>
          </li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Notification</b>: March 5, 2025, (AOE)</li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Camera-ready</b>: March 19, 2025</li>
        </ul>
        Deadlines are strict and will not be extended under any circumstances. All deadlines follow the <a href="https://time.is/Anywhere_on_Earth">Anywhere on Earth (AoE)</a> timezone.
        <br>
        <br>
        <h3>Submission Site</h3>
        <p>
          Submissions will be managed via OpenReview. Papers will remain private during the review process. All authors must maintain up-to-date OpenReview profiles to ensure proper conflict-of-interest management and paper matching. Incomplete profiles may result in desk rejection.  
          <a href="https://docs.openreview.net/getting-started/creating-an-openreview-profile">Learn how to create an OpenReview profile here</a>.
          <br>
          <br>
          Submit papers through the Reasoning and Planning for LLMs Workshop Submission Portal on OpenReview (<a href="https://openreview.net/group?id=ICLR.cc/2025/Workshop/LLM_Reason_and_Plan#tab-your-consoles" target="_blank">Reasoning and Planning for LLMs Workshop Submission Portal</a>).
        </p>

        <h3>Scope</h3>
        We welcome contributions across a broad spectrum of topics, including but not limited to:
        <ul class="fa-ul">
          <li><span class="fa-li"><i class="fa fa-check"></i></span>Training methodologies for enhancing reasoning and planning in LLMs</li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span>Efficient inference for complex reasoning tasks</li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span>Benchmarking reasoning and planning capabilities</li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span>Multi-modality and embodiment in LLMs</li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span>Emerging trends in LLM reasoning and planning</li>
        </ul>
        Accepted papers will be presented as posters, with a subset selected for oral presentations. The workshop will take place in person at ICLR 2025, with virtual participation options to be confirmed.

        <br>
        <br>
        <h3>Submission Guidelines</h3>
        <h5>Formatting Requirements</h5>

        Submissions must be in English and follow the <a href="https://www.overleaf.com/read/dgcnvnhjxwcg#335f8d">Reasoning and Planning for LLMs Workshop LaTeX Template</a> (adapted from the ICLR 2025 template).  
        <br>
        <br>
        Papers must be submitted as a <b>single PDF file</b>:  
        <ul class="fa-ul">
          <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Long Papers</b>: at most 9 pages (main text)</li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Tiny Papers</b>: between 2 and 4 pages (main text)</li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span>References and appendices are not included in the page limit, but the main text must be self-contained. Reviewers are not required to read beyond the main text.</li>
        </ul>

        <p>Submissions exceeding the page limit will be desk rejected.</p>

        <h5>Anonymity</h5>
        The workshop follows a <b>double-blind review process</b>. Submissions must be anonymized by removing author names, affiliations, and acknowledgments. Prior work should be cited in the third person. Identifying information, including in supplementary materials, must be omitted.
        <br>
        <br>
        <h5>Dual Submission and Non-Archival Policy</h5>
        Submissions under review at other venues will be accepted, provided they do not breach any dual-submission or anonymity policies of those venues. Submissions will not be indexed or have archival proceedings. We welcome ICML 25 or ACL 25 submissions.
        <br>
        <br>
        <h5>Transparency</h5>
        By submitting to the Reasoning and Planning for LLMs Workshop, authors agree that for all accepted papers, the original submission, reviews, and meta-reviews will be made publicly available on OpenReview.
        <br>
        <br>
        <h5>Contact</h5>
        Email at zhiyuanhucs@gmail.com
      </div>
    </section>

    <br>
    <br>
    <section id="accepted-paper">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Accepted Paper</h2>
        </div>

        <!-- Poster Presentations (dynamic load) -->
        <div class="mb-3" style="border: 1px solid #ddd; border-radius: 5px;">
          <div style="background-color: #e2eeff; padding: 10px; cursor: pointer; font-weight: 500; display: flex; justify-content: space-between; align-items: center;"
            data-bs-toggle="collapse" data-bs-target="#poster-presentations" aria-expanded="true"
            aria-controls="poster-presentations">
            <span>Accepted Papers</span>
            <i class="bi bi-chevron-up"></i>
          </div>
          <div class="collapse" id="poster-presentations">
            <div style="padding: 15px;">
              <!-- Here we place an empty <ul> that we'll fill using JavaScript -->
              <ul id="posterList" style="margin-bottom: 0;"></ul>
            </div>
          </div>
        </div>
      </div>
    </section>

    <br>
    <br>
    <section id="grant">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Student Registration Grant</h2>
        </div>
        <p>
          We are excited to offer a limited number of free full conference, “student early” registrations for ICLR 2025, exclusively for full-time students attending in person. This initiative aims to support early-career researchers while fostering diversity, equity, and inclusion (DEI) in the academic community.
        </p>
        <h3>Selection Criteria</h3>
        <p>
          Applications will be evaluated based on the strength of the submitted materials (see details below). Priority will be given to students presenting papers at our workshop who lack alternative travel support.
        </p>
        <h3>How to Apply</h3>
        <p>
          Interested students must complete the application form <a href="https://forms.gle/6Q7ZVV7TeHAL6pPG8">here</a> by <b>11:59pm (AoE) on March 5, 2025</b>, which includes the following:
        </p>
        <ul>
          <li><b>Personal &amp; Academic Details</b>: Name, affiliation, and relevant academic information</li>
          <li><b>CV/Resume</b></li>
          <li><b>Paper ID</b>: Accepted or submitted to our workshop</li>
          <li><b>Statement of Interest</b>: A brief paragraph explaining how this opportunity will benefit your research and career</li>
          <li><b>Attendance Confirmation</b>: A clear statement confirming that you will attend in person</li>
        </ul>
        <h3>Important Notes</h3>
        <ul>
          <li>Awardees will be announced in March 10, 2025</li>
          <li>If you have already registered, please submit your receipt, and we will provide further instructions</li>
          <li>Travel and accommodations must be arranged independently—this grant covers registration only</li>
        </ul>
        <p>
          This opportunity is highly competitive, and we encourage all eligible students to apply early!
        </p>

        <h3>Registration Grant Recipients</h3>
        <ul>
          <li><b>Gonzalo Gonzalez-Pumariega</b> – Cornell University</li>
          <li><b>Niklas Muennighoff</b> – Stanford University</li>
          <li><b>Annya Dahmani</b> – University of California, Berkeley</li>
          <li><b>Constantin Venhoff</b> – Oxford University</li>
          <li><b>Harshita Chopra</b> – University of Washington</li>
          <li><b>Yongchao Chen</b> – Harvard University</li>
          <li><b>Bo Liu</b> – National University of Singapore</li>
          <li><b>Xingcheng Yao</b> – University of California, Los Angeles</li>
          <li><b>Fangru Lin</b> – Oxford University</li>
          <li><b>Chenchen Ye</b> – University of California, Los Angeles</li>
          <li><b>Tsz Hang Wong</b> – Imperial College London</li>
          <li><b>Hui Yuan</b> – Princeton University</li>
        </ul>
      </div>
    </section>

    <section id="speakers" class="section-with-bg">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Speakers and Panelists (Tentative)</h2>
        </div>

        <div class="row">
          <div class="col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/speakers/speaker_1_.jpg" alt="Sheila McIlraith" class="img-fluid">
              <br><a href="https://www.cs.toronto.edu/~sheila/" style="font-size: 1.2em; color: #00356B;">Sheila McIlraith</a></br>
              <p>University of Toronto<br>
                (Fellow of ACM, Fellow of AAAI)</p>
            </div>
          </div>

          <div class="col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/speakers/speaker_2.jpg" alt="Guy Van den Broeck" class="img-fluid">
              <br><a href="https://web.cs.ucla.edu/~guyvdb/" style="font-size: 1.2em; color: #00356B;">Guy Van den Broeck</a></br>
              <p>UCLA<br>
                (Sloan Fellowship)</p>
            </div>
          </div>

          <div class="col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/speakers/speaker_3_.jpg" alt="Hongyu Ren" class="img-fluid">
              <br><a href="http://hyren.me/" style="font-size: 1.2em; color: #00356B;">Hongyu Ren</a></br>
              <p>OpenAI<br>
                (Foundational Contributor of OpenAI o1)</p>
            </div>
          </div>

          <div class="col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/speakers/speaker_4_.png" alt="Yuandong Tian" class="img-fluid">
              <br><a href="https://yuandong-tian.com/" style="font-size: 1.2em; color: #00356B;">Yuandong Tian</a></br>
              <p>Meta<br>
                (Research Scientist Director in FAIR)
              </p>
            </div>
          </div>

          <div class="col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/speakers/speaker_5_2_.jpg" alt="Natasha Jaques" class="img-fluid">
              <br><a href="https://natashajaques.ai/" style="font-size: 1.2em; color: #00356B;">Natasha Jaques</a></br>
              <p>University of Washington &amp; Google DeepMind<br>
                (ICML Best Paper Honourable Mention)
              </p>
            </div>
          </div>

          <div class="col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/speakers/speaker_6_.jpg" alt="Bo An" class="img-fluid">
              <br><a href="https://personal.ntu.edu.sg/boan/" style="font-size: 1.2em; color: #00356B;">Bo An</a></br>
              <p>NTU<br>
                (PC Chair of IJCAI’27)
              </p>
            </div>
          </div>

          <div class="col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/speakers/speaker_7_2.jpeg" alt="Stephen McAleer" class="img-fluid">
              <br><a href="https://mcaleste.github.io/" style="font-size: 1.2em; color: #00356B;">Stephen McAleer</a></br>
              <p>OpenAI</p>
            </div>
          </div>

          <div class="col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/speakers/speaker_8.jpg" alt="Junxian He" class="img-fluid">
              <br><a href="https://jxhe.github.io/" style="font-size: 1.2em; color: #00356B;">Junxian He</a></br>
              <p>HKUST</p>
            </div>
          </div>

        </div>
      </div>
    </section>

    <section id="organizers">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Organizers</h2>
          <p>This workshop is organized by</p>
        </div>

        <div class="row">
          <div class="col-lg-2 col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/zhiyuan.jpg" alt="Zhiyuan Hu" class="img-fluid">
              <br><a href="https://zhiyuanhubj.github.io/" style="font-size: 1.2em; color: #00356B;">Zhiyuan Hu</a></br>
              <p>NUS</p>
            </div>
          </div>

          <div class="col-lg-2 col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/yilun.jpeg" alt="Yilun Zhao" class="img-fluid">
              <br><a href="https://yilunzhao.github.io/" style="font-size: 1.2em; color: #00356B;">Yilun Zhao</a></br>
              <p>Yale</p>
            </div>
          </div>

          <div class="col-lg-2 col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/xidong.jpg" alt="Xidong Feng" class="img-fluid">
              <br><a href="https://waterhorse1.github.io/" style="font-size: 1.2em; color: #00356B;">Xidong Feng</a></br>
              <p>Google DeepMind</p>
            </div>
          </div>

          <div class="col-lg-2 col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/min.jpg" alt="Min-Yen Kan" class="img-fluid">
              <br><a href="https://www.comp.nus.edu.sg/~kanmy/" style="font-size: 1.2em; color: #00356B;">Min-Yen Kan</a></br>
              <p>NUS</p>
            </div>
          </div>

          <div class="col-lg-2 col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/yali.png" alt="Yali Du" class="img-fluid">
              <br><a href="https://yalidu.github.io/" style="font-size: 1.2em; color: #00356B;">Yali Du</a></br>
              <p>KCL</p>
            </div>
          </div>

          <div class="col-lg-2 col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/jiaying.png" alt="Jiaying Wu" class="img-fluid">
              <br><a href="https://jiayingwu19.github.io/" style="font-size: 1.2em; color: #00356B;">Jiaying Wu</a></br>
              <p>NUS</p>
            </div>
          </div>

          <div class="col-lg-2 col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/canyu.jpg" alt="Canyu Chen" class="img-fluid">
              <br><a href="https://canyuchen.com/" style="font-size: 1.2em; color: #00356B;">Canyu Chen</a></br>
              <p>Illinois Tech</p>
            </div>
          </div>

          <div class="col-lg-2 col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/nouha.jpg" alt="Nouha Dziri" class="img-fluid">
              <br><a href="https://nouhadziri.github.io/" style="font-size: 1.2em; color: #00356B;">Nouha Dziri</a></br>
              <p>AI2</p>
            </div>
          </div>

          <div class="col-lg-2 col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/pang.jpg" alt="Pang Wei Koh" class="img-fluid">
              <br><a href="https://koh.pw/" style="font-size: 1.2em; color: #00356B;">Pang Wei Koh</a></br>
              <p>UW</p>
            </div>
          </div>

          <div class="col-lg-2 col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/arman.jpg" alt="Arman Cohan" class="img-fluid">
              <br><a href="https://armancohan.com/" style="font-size: 1.2em; color: #00356B;">Arman Cohan</a></br>
              <p>Yale</p>
            </div>
          </div>

          <div class="col-lg-2 col-md-3 col-sm-4 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/bryan.jpg" alt="Bryan Hooi" class="img-fluid">
              <br><a href="https://bhooi.github.io/" style="font-size: 1.2em; color: #00356B;">Bryan Hooi</a></br>
              <p>NUS</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section id="sponser">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Sponsors</h2>
          <p>We thank our sponsors for their generous support!</p>
        </div>

        <div class="row">
          <div class="col-lg-3 col-md-4 col-sm-6 col-8">
            <div class="sponser" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/sponsors/huawei.png" alt="Huawei" class="img-fluid">
            </div>
          </div>
          <div class="col-12 col-sm-4 col-md-6">
            <div class="sponser" data-aos="fade-up" data-aos-delay="200" style="text-align: center; margin-top: 5%;">
              <img src="assets/img/sponsors/tiktok.webp" alt="Tiktok" class="img-fluid">
            </div>
          </div>
        </div>
      </div>
    </section>
    <br>
    <br>

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        <!-- &copy; Copyright <strong>TheEvent</strong>. All Rights Reserved -->
      </div>
      <div class="credits">
        Template adopted from <a href="https://set-llm.github.io/">SeT LLM @ ICLR 2024</a>
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

  <!-- ======= Dynamic Loading Script ======= -->
  <script>
    // This example assumes accepted_paper.json is located in the same directory as your HTML file.
    // Adjust the path as necessary.
    fetch('accepted_paper.json')
      .then(response => response.json())
      .then(data => {
        const posterList = document.getElementById('posterList');
        
        // In the snippet, the data in accepted_paper.json is an object with a "notes" array
        // that holds the accepted papers
        const notes = data.notes;  // e.g. data.notes = [{ content: {...}, ...}, ...]

        notes.forEach(item => {
          const title = item.content.title.value;
          // Authors may be stored as an array in item.content.authors.value or a single string, depending on your JSON
          // If it's an array, join them
          const authorsVal = item.content.authors.value;
          let authors = Array.isArray(authorsVal) ? authorsVal.join(", ") : authorsVal;

          const li = document.createElement('li');
          li.innerHTML = `
            <b>${title}</b><br>
            Authors: ${authors}
          `;
          posterList.appendChild(li);

          // Add some spacing after each paper
          const br = document.createElement('br');
          posterList.appendChild(br);
        });
      })
      .catch(error => {
        console.error('Error loading accepted_paper.json:', error);
      });
  </script>

  <a href="https://info.flagcounter.com/fIO5"><img src="https://s05.flagcounter.com/count2/fIO5/bg_FFFFFF/txt_000000/border_CCCCCC/columns_6/maxflags_20/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>

</body>

</html>
